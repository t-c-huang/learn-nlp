# learn-nlp
This note is referred to the repository [`graykode/nlp-tutorial`](https://github.com/graykode/nlp-tutorial).


# Curriculum
## Word2vec
- [The Illustrated Word2vec – Jay Alammar – Visualizing machine learning one concept at a time.](https://jalammar.github.io/illustrated-word2vec/)

## Attention Mechanism
- **Neural Machine Translation by Jointly Learning to Align and Translate (2014)**
    - [Paper link](https://arxiv.org/pdf/1409.0473.pdf)
    - [My note](https://hackmd.io/@SdjvZ5D6QQOX2P6Ec3rJMg/SJAKeN91t)
## Transformer
- **Attention Is All You Need (2017)**
    - [Paper link](https://arxiv.org/pdf/1706.03762.pdf)
    - [My note](https://hackmd.io/@SdjvZ5D6QQOX2P6Ec3rJMg/attention-is-all-you-need)
- [The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.](jalammar.github.io)

## GPT2
- **Language Models are Unsupervised Multitask Learners**
    - [Paper link](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
    - [My note](https://hackmd.io/@SdjvZ5D6QQOX2P6Ec3rJMg/GPT2)
- [The Illustrated GPT-2 (Visualizing Transformer Language Models)](https://jalammar.github.io/illustrated-gpt2/)

## BERT
- **BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**
    - [Paper link](https://arxiv.org/pdf/1810.04805.pdf)
    - [My note](https://hackmd.io/@SdjvZ5D6QQOX2P6Ec3rJMg/BERT)
- [The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)](https://jalammar.github.io/illustrated-bert/)


